{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries \n",
    "# Keras\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Other  \n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import wave\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import python_speech_features as ps\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import math\n",
    "import time\n",
    "from scipy import signal\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimVoice(data, sokuonleng = 3, spaceleng = 10, voiceleng= 10, debug=False):\n",
    "    trimpoint = detectVoice(data, sokuonleng = sokuonleng, spaceleng=spaceleng, voiceleng = voiceleng, debug=debug)\n",
    "    trimdata = []\n",
    "    for point in trimpoint:\n",
    "        trimdata.append(data[point[0]:point[1]])\n",
    "    return trimdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectVoice(data, sokuonleng = 3, spaceleng = 10, voiceleng= 10, debug=False):\n",
    "    zscore = np.empty_like(data)\n",
    "    eps = 1e-5\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    zscore = (data - mean)/(std+eps)\n",
    "    zscore = np.append(zscore, np.zeros(1024 - zscore.shape[0] % 1024),0)\n",
    "    zscore = zscore.reshape(-1, 1024)\n",
    "    ave = np.empty((1,), float)\n",
    "    diff = np.empty((0,), float)\n",
    "    silent = 0\n",
    "    voice = 0\n",
    "    isVoice = 0\n",
    "    standby = 0\n",
    "    voiceOnWave = np.empty((0,2), int)\n",
    "    warn = False\n",
    "    for waddr in range(zscore.shape[0]):\n",
    "        ave = np.append(ave, np.mean(np.abs(zscore[waddr])))\n",
    "        diff = np.append(diff, ave[-2]-ave[-1])\n",
    "        #print(np.abs(diff[waddr]) > 0)\n",
    "        #声の部分か判定する。\n",
    "        if np.abs(diff[waddr]) > 0.05:\n",
    "            silent = 0\n",
    "            voice  = sokuonleng\n",
    "        else:\n",
    "            silent += 1\n",
    "            voice  -= 1 if voice > 0 else 0\n",
    "        #発話していないなら\n",
    "        if isVoice == 0:\n",
    "            if standby == -1:\n",
    "                #スタンバイでない時、音を検知したら、スタンバイする(その時の時間を覚えておく)。\n",
    "                if voice == sokuonleng:\n",
    "                    standby = waddr - 1 #発声する瞬間も大事な特微量なので、現在のアドレスより1コマ過去のものから判定開始\n",
    "            else:\n",
    "                if waddr-standby >= voiceleng:\n",
    "                    #voiceleng以上発話していれば、isRecをアクティブに。\n",
    "                    if voice != 0:\n",
    "                        if debug == True:\n",
    "                            print(\"Record start{}\".format(standby, waddr))\n",
    "                        isVoice = 1\n",
    "                        voiceOnWave = np.append(voiceOnWave, np.zeros((1,2), int),0)\n",
    "                        voiceOnWave[-1,0] = standby*1024\n",
    "                    #voicelengより短い発話だったら、スタンバイ解除\n",
    "                    elif voice == 0:\n",
    "                        standby = -1\n",
    "                elif silent >= spaceleng:\n",
    "                    standby = -1\n",
    "                \n",
    "        #発話しているなら\n",
    "        else:\n",
    "            #もしも、一定時間以上静寂なら、isRecをディスアクティブに。\n",
    "            if silent >= spaceleng or waddr == zscore.shape[0]-1:\n",
    "                if debug == True:\n",
    "                    print(\"--->{}\".format(waddr-spaceleng, waddr))\n",
    "                isVoice = 0\n",
    "                standby = -1\n",
    "                voiceOnWave[-1,1] = (waddr - silent +5)*1024 #+5して発話後に若干余白をとる。\n",
    "    return voiceOnWave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadwav(path, mono=True):\n",
    "    file = wave.open(path, 'r')\n",
    "    params = file.getparams()\n",
    "    nchannels, samplewidth, samplerate, wav_length = params[:4]\n",
    "    datatype = {2:\"int16\", 4:\"int32\"}\n",
    "    str_data = file.readframes(wav_length)\n",
    "    data = np.frombuffer(str_data, dtype = np.short)\n",
    "    if(nchannels == 2):\n",
    "        left = data[::2]\n",
    "        right= data[1::2]\n",
    "        wavedata = np.stack([left, right], 1)\n",
    "        if mono == True:\n",
    "            wavedata = np.mean(wavedata, axis=1)\n",
    "            wavedata = wavedata.astype(datatype[samplewidth])\n",
    "    else:\n",
    "        wavedata = data\n",
    "    return wavedata, samplerate, samplewidth, nchannels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savewav(data, path):\n",
    "    outd = struct.pack(\"h\" * len(data), *data)\n",
    "    with wave.open(path, 'w') as ww:\n",
    "        ww.setnchannels(nchannel)\n",
    "        ww.setsampwidth(samplewidt)\n",
    "        ww.setframerate(samplerate)\n",
    "        ww.writeframes(outd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mellCepstrum(data, RATE, winlen=0.08, winstep=0.016, nfilt=40, start=None, end=None):\n",
    "    data = np.append(data, np.zeros(1024 - data.shape[0] % 1024),0)\n",
    "    eps = 1e-5\n",
    "    if start == None and end == None:\n",
    "        mel_spec = ps.logfbank(data, samplerate=RATE, winlen=winlen, winstep=winstep, nfilt=nfilt, nfft=int(winlen*RATE))\n",
    "    elif start == None or end == None:\n",
    "        point = start if end == None else end\n",
    "        mel_spec = ps.logfbank(data[point], samplerate=RATE, winlen=winlen, winstep=winstep, nfilt=nfilt, nfft=int(winlen*RATE))\n",
    "    else:\n",
    "        mel_spec = ps.logfbank(data[start:end], samplerate=RATE, winlen=winlen, winstep=winstep, nfilt=nfilt, nfft=int(winlen*RATE))\n",
    "    #deltaの特微量を生成\n",
    "    delta1= ps.delta(mel_spec, 4)\n",
    "    #delta-deltaの特微量を生成\n",
    "    delta2 = ps.delta(delta1, 4)\n",
    "    mean1 = np.mean(mel_spec)\n",
    "    mean2 = np.mean(delta1)\n",
    "    mean3 = np.mean(delta2)\n",
    "    std1 = np.std(mel_spec)\n",
    "    std2 = np.std(delta1)\n",
    "    std3 = np.std(delta2)\n",
    "    procd = np.empty((mel_spec.shape[0], nfilt, 3))\n",
    "    procd[:,:,0] = (mel_spec - mean1)/(std1+eps) #mel_spec\n",
    "    procd[:,:,1] = (delta1 - mean2)/(std2+eps) #delta1\n",
    "    procd[:,:,2] = (delta2 - mean3)/(std3+eps) #delta2\n",
    "    return procd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverselabel(value):\n",
    "    tag = {'female_angry':0, 'female_disgust':1, 'female_fear':2, 'female_happy':3,\n",
    " 'female_neutral':4, 'female_sad':5, 'female_surprise':6, 'male_angry':7,\n",
    " 'male_disgust':8, 'male_fear':9, 'male_happy':10, 'male_neutral':11, 'male_sad':12,\n",
    " 'male_surprise':13}\n",
    "    return [k for k, v in tag.items() if v == value][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# loading json and model architecture \n",
    "json_file = open('model_json.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"saved_models/Emotion_Model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>source</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male_sad</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>/Users/naokitakatani/Documents/datasets/SAVEE/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male_sad</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>/Users/naokitakatani/Documents/datasets/SAVEE/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male_neutral</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>/Users/naokitakatani/Documents/datasets/SAVEE/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male_surprise</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>/Users/naokitakatani/Documents/datasets/SAVEE/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male_neutral</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>/Users/naokitakatani/Documents/datasets/SAVEE/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          labels source                                               path\n",
       "0       male_sad  SAVEE  /Users/naokitakatani/Documents/datasets/SAVEE/...\n",
       "1       male_sad  SAVEE  /Users/naokitakatani/Documents/datasets/SAVEE/...\n",
       "2   male_neutral  SAVEE  /Users/naokitakatani/Documents/datasets/SAVEE/...\n",
       "3  male_surprise  SAVEE  /Users/naokitakatani/Documents/datasets/SAVEE/...\n",
       "4   male_neutral  SAVEE  /Users/naokitakatani/Documents/datasets/SAVEE/..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets pick up the meta-data that we got from our first part of the Kernel\n",
    "ref = pd.read_csv(\"/Users/naokitakatani/Documents/2020_12_12_SERv3/Data_path.csv\")\n",
    "ref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.empty((0,300,40,3),float)\n",
    "emolabel = np.zeros(0,int)\n",
    "setindex = np.zeros(0,int)\n",
    "start = 0\n",
    "b, a = signal.iirfilter(2, 1500,btype='highpass',rs = 60,rp = 1.0, ftype='ellip',output='ba',fs=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.261 path : /Users/naokitakatani/Documents/datasets/SAVEE/KL_f15.wav\n",
      "No.262 path : /Users/naokitakatani/Documents/datasets/SAVEE/DC_a14.wav\n",
      "No.263 path : /Users/naokitakatani/Documents/datasets/SAVEE/KL_d03.wav\n",
      "No.264 path : /Users/naokitakatani/Documents/datasets/SAVEE/JK_su06.wav\n",
      "No.265 path : /Users/naokitakatani/Documents/datasets/SAVEE/JK_su12.wav\n",
      "No.266 path : /Users/naokitakatani/Documents/datasets/SAVEE/JE_n23.wav\n",
      "No.267 path : /Users/naokitakatani/Documents/datasets/SAVEE/JE_f02.wav\n",
      "No.268 path : /Users/naokitakatani/Documents/datasets/SAVEE/KL_su14.wav\n",
      "No.269 path : /Users/naokitakatani/Documents/datasets/SAVEE/JE_d14.wav\n",
      "No.270 path : /Users/naokitakatani/Documents/datasets/SAVEE/KL_n08.wav\n",
      "No.271 path : /Users/naokitakatani/Documents/datasets/SAVEE/KL_n20.wav\n",
      "No.272 path : /Users/naokitakatani/Documents/datasets/SAVEE/KL_n18.wav\n",
      "No.273 path : /Users/naokitakatani/Documents/datasets/SAVEE/KL_n24.wav\n",
      "No.274 path : /Users/naokitakatani/Documents/datasets/SAVEE/KL_n30.wav\n",
      "No.275 path : /Users/naokitakatani/Documents/datasets/SAVEE/JE_d04.wav\n",
      "No.276 path : /Users/naokitakatani/Documents/datasets/SAVEE/JE_d10.wav\n",
      "No.277 path : /Users/naokitakatani/Documents/datasets/SAVEE/KL_su04.wav\n",
      "No.278 path : /Users/naokitakatani/Documents/datasets/SAVEE/JE_h09.wav\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-2f333abe90d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mappend\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Documents/2020_12_22_realtime_SERv3/env/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   4669\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4670\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4671\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for index, (label, path) in enumerate(zip(ref.labels, ref.path)):\n",
    "    if index == start: \n",
    "        if features.shape[0] == index:\n",
    "            features = np.append(features,np.zeros((1,300,40,3),float),0)\n",
    "        elif features.shape[0] != index + 1:\n",
    "            sys.exit()\n",
    "        print(\"No.{} path : {}\".format(index, path))\n",
    "        try:\n",
    "            X, samplerate,samplewidth,nchannel = loadwav(path)\n",
    "            trimdata = trimVoice(X, spaceleng = 30)\n",
    "            Y = trimdata[0]\n",
    "            heatmap_data = mellCepstrum(Y, samplerate)\n",
    "            end = heatmap_data.shape[0] if heatmap_data.shape[0] <= 300 else 300\n",
    "            features[-1,:end] = heatmap_data[:end]\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"KeyboardInterrupt\")\n",
    "            sys.exit()\n",
    "        #except:\n",
    "         #   print(\"Skip this audio file.\")\n",
    "        start += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/17 [==>...........................] - ETA: 2:30"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-674e04895476>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m preds = loaded_model.predict(features, \n\u001b[1;32m      2\u001b[0m                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                          verbose=1)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#13の感情のなかから最も高い値(確率が高い感情)を選ぶ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/2020_12_22_realtime_SERv3/env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/2020_12_22_realtime_SERv3/env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/2020_12_22_realtime_SERv3/env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/Documents/2020_12_22_realtime_SERv3/env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/2020_12_22_realtime_SERv3/env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/2020_12_22_realtime_SERv3/env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/Documents/2020_12_22_realtime_SERv3/env/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "preds = loaded_model.predict(features, \n",
    "                         batch_size=16, \n",
    "                         verbose=1)\n",
    "#13の感情のなかから最も高い値(確率が高い感情)を選ぶ\n",
    "preds=preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"nonFilterFeatures.pkl\", \"wb\") as file:\n",
    "    pickle.dump((features, preds), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.empty((0,300,40,3),float)\n",
    "emolabel = np.zeros(0,int)\n",
    "setindex = np.zeros(0,int)\n",
    "start = 0\n",
    "b, a = signal.iirfilter(2, 1500,btype='highpass',rs = 60,rp = 1.0, ftype='ellip',output='ba',fs=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (label, path) in enumerate(zip(ref.labels, ref.path)):\n",
    "    if index == start: \n",
    "        if features.shape[0] == index:\n",
    "            features = np.append(features,np.zeros((1,300,40,3),float),0)\n",
    "        elif features.shape[0] != index + 1:\n",
    "            sys.exit()\n",
    "        print(\"No.{} path : {}\".format(index, path))\n",
    "        try:\n",
    "            X, samplerate,samplewidth,nchannel = loadwav(path)\n",
    "            trimdata = trimVoice(X, spaceleng = 30)\n",
    "            Y = signal.lfilter(b, a, trimdata[0])\n",
    "            heatmap_data = mellCepstrum(Y, samplerate)\n",
    "            end = heatmap_data.shape[0] if heatmap_data.shape[0] <= 300 else 300\n",
    "            features[-1,:end] = heatmap_data[:end]\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"KeyboardInterrupt\")\n",
    "            sys.exit()\n",
    "        #except:\n",
    "         #   print(\"Skip this audio file.\")\n",
    "        start += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = loaded_model.predict(features, \n",
    "                         batch_size=16, \n",
    "                         verbose=1)\n",
    "#13の感情のなかから最も高い値(確率が高い感情)を選ぶ\n",
    "preds=preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"FilteredFeatures.pkl\", \"wb\") as file:\n",
    "    pickle.dump((features, preds), file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
